{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NAFNet: Nonlinear Activation Free Network\n",
        "\n",
        "**Image Deblurring**"
      ],
      "metadata": {
        "id": "8JI3vDyk_Idn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup\n",
        "\n",
        "**Clone repo and install dependencies. **"
      ],
      "metadata": {
        "id": "kdfuLYPRiAry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn1wnYiQHLCg",
        "outputId": "0bd9e7ce-1199-476e-d8de-ca3a1f374a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NAFNet'...\n",
            "remote: Enumerating objects: 517, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 517 (delta 140), reused 112 (delta 112), pack-reused 356\u001b[K\n",
            "Receiving objects: 100% (517/517), 16.19 MiB | 39.01 MiB/s, done.\n",
            "Resolving deltas: 100% (271/271), done.\n",
            "/content/NAFNet/NAFNet/NAFNet\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/megvii-research/NAFNet\n",
        "%cd NAFNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!python3 setup.py develop --no_cuda_ext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-MVdSsJHnPj",
        "outputId": "dd7e0cd8-6463-4234-bff8-2d2266f6e0ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (0.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (2.12.0a20221220)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (0.32.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.8.8)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (3.19.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.38.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (2.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.51.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tb-nightly->-r requirements.txt (line 11)) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 11)) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "running develop\n",
            "running egg_info\n",
            "creating basicsr.egg-info\n",
            "writing basicsr.egg-info/PKG-INFO\n",
            "writing dependency_links to basicsr.egg-info/dependency_links.txt\n",
            "writing top-level names to basicsr.egg-info/top_level.txt\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.8/dist-packages/basicsr.egg-link (link to .)\n",
            "Removing basicsr 1.2.0+50cb149 from easy-install.pth file\n",
            "Adding basicsr 1.2.0+50cb149 to easy-install.pth file\n",
            "\n",
            "Installed /content/NAFNet/NAFNet/NAFNet\n",
            "Processing dependencies for basicsr==1.2.0+50cb149\n",
            "Finished processing dependencies for basicsr==1.2.0+50cb149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download pretrained models"
      ],
      "metadata": {
        "id": "FUZSEIxYiywI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=14D4V4raNYIOhETfcuuLI3bGLB-OYIv6X', \"./experiments/pretrained_models/\", quiet=False) # deblurring\n",
        "\n",
        "#gdown.download('https://drive.google.com/uc?id=14Fht1QQJ2gMlk4N1ERCRuElg8JfjrWWR', \"./experiments/pretrained_models/\", quiet=False) # denoising"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "DiElLLM2HS4D",
        "outputId": "dfd230af-c31f-487e-eb5d-1ce0d7fde740"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14D4V4raNYIOhETfcuuLI3bGLB-OYIv6X\n",
            "To: /content/NAFNet/NAFNet/NAFNet/experiments/pretrained_models/NAFNet-REDS-width64.pth\n",
            "100%|██████████| 272M/272M [00:03<00:00, 72.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./experiments/pretrained_models/NAFNet-REDS-width64.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Mounting Google Drive to uplaod the images from"
      ],
      "metadata": {
        "id": "R1ZU5PSHjjo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/google-drive')\n",
        "\n",
        "drive_dir = \"/content/google-drive/Shareddrives/DeepLearning/skulldatasets\"\n",
        "\n",
        "input_dir = drive_dir + '/v1/input-blurry'\n",
        "out_dir = drive_dir + '/v1/Nafnet-deblurring'"
      ],
      "metadata": {
        "id": "HVTe-4v6uwEU",
        "outputId": "941af88b-4eeb-414e-8425-db836b01c8d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/google-drive; to attempt to forcibly remount, call drive.mount(\"/content/google-drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ],
      "metadata": {
        "id": "EA7GsVUHsvac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from basicsr.models import create_model\n",
        "from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite\n",
        "from basicsr.utils.options import parse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "def img2tensor(img, bgr2rgb=False, float32=True):\n",
        "    img = img.astype(np.float32) / 255.\n",
        "    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)\n",
        "\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1) \n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('NAFNet output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "\n",
        "def single_image_inference(model, img, save_path):\n",
        "      model.feed_data(data={'lq': img.unsqueeze(dim=0)})\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids()\n",
        "\n",
        "      model.test()\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids_inverse()\n",
        "\n",
        "      visuals = model.get_current_visuals()\n",
        "      sr_img = tensor2img([visuals['result']])\n",
        "      imwrite(sr_img, save_path)\n"
      ],
      "metadata": {
        "id": "_RKjUG_IIWb2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_path = 'options/test/REDS/NAFNet-width64.yml'\n",
        "#opt_path = 'options/test/SIDD/NAFNet-width64.yml'\n",
        "opt = parse(opt_path, is_train=False)\n",
        "opt['dist'] = False\n",
        "NAFNet = create_model(opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS3Hbplm2ORH",
        "outputId": "3114bd7b-216a-49c1-85c9-da1fb45117c6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " load net keys <built-in method keys of dict object at 0x7f36e586c940>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Inference"
      ],
      "metadata": {
        "id": "5zkKKgsTj7mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "input_list = sorted(glob.glob(os.path.join(input_dir, '*')))\n",
        "for input_path in input_list:\n",
        "  img_input = imread(input_path)\n",
        "  inp = img2tensor(img_input)\n",
        "  output_path = os.path.join(out_dir, os.path.basename(input_path))\n",
        "  single_image_inference(NAFNet, inp, output_path)"
      ],
      "metadata": {
        "id": "ZvTFR-LKj9_6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize Results"
      ],
      "metadata": {
        "id": "bHA9Co42dKV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "input_list = sorted(glob.glob(os.path.join(input_dir, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(out_dir, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ],
      "metadata": {
        "id": "MrvOjmr2dNy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. PSNR Measurement on patches"
      ],
      "metadata": {
        "id": "qqerXolVtF74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "from pdb import set_trace as stx\n",
        "import random\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['jpeg', 'JPEG', 'jpg', 'png', 'JPG', 'PNG', 'gif'])\n",
        "\n",
        "\n",
        "class DataLoaderVal(Dataset):\n",
        "    def __init__(self, rgb_dir, input_dir, target_dir, img_options=None, rgb_dir2=None):\n",
        "        super(DataLoaderVal, self).__init__()\n",
        "\n",
        "        inp_files = sorted(os.listdir(os.path.join(rgb_dir, input_dir)))\n",
        "        tar_files = sorted(os.listdir(os.path.join(rgb_dir, target_dir)))\n",
        "\n",
        "        self.inp_filenames = [os.path.join(rgb_dir, input_dir, x)  for x in inp_files if is_image_file(x)]\n",
        "        self.tar_filenames = [os.path.join(rgb_dir, target_dir, x) for x in tar_files if is_image_file(x)]\n",
        "\n",
        "        self.img_options = img_options\n",
        "        self.sizex       = len(self.tar_filenames)  # get the size of target\n",
        "\n",
        "        self.ps = self.img_options['patch_size']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sizex\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index_ = index % self.sizex\n",
        "        ps = self.ps\n",
        "\n",
        "        inp_path = self.inp_filenames[index_]\n",
        "        tar_path = self.tar_filenames[index_]\n",
        "\n",
        "        inp_img = Image.open(inp_path)\n",
        "        tar_img = Image.open(tar_path)\n",
        "\n",
        "        # Validate on center crop\n",
        "        if self.ps is not None:\n",
        "            inp_img = TF.center_crop(inp_img, (ps,ps))\n",
        "            tar_img = TF.center_crop(tar_img, (ps,ps))\n",
        "\n",
        "        inp_img = TF.to_tensor(inp_img)\n",
        "        tar_img = TF.to_tensor(tar_img)\n",
        "\n",
        "        filename = os.path.splitext(os.path.split(tar_path)[-1])[0]\n",
        "\n",
        "        return tar_img, inp_img, filename"
      ],
      "metadata": {
        "id": "ylCgEvGt03il"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torchPSNR(tar_img, prd_img):\n",
        "    imdff = torch.clamp(prd_img,0,1) - torch.clamp(tar_img,0,1)\n",
        "    rmse = (imdff**2).mean().sqrt()\n",
        "    ps = 20*torch.log10(1/rmse)\n",
        "    return ps\n",
        "\n",
        "def get_validation_data(rgb_dir, img_options, input_dir, target_dir ):\n",
        "    assert os.path.exists(rgb_dir)\n",
        "    return DataLoaderVal(rgb_dir, input_dir, target_dir, img_options)\n",
        "\n",
        "def get_pnsr(data_loader, model=None):\n",
        "    psnr_val_rgb = []\n",
        "    for ii, data_val in enumerate((data_loader), 0):\n",
        "        target = data_val[0].cuda()\n",
        "        input_ = data_val[1].cuda()\n",
        "        restored = input_\n",
        "\n",
        "        # if model:\n",
        "        #     # model.eval()\n",
        "        #     with torch.no_grad():\n",
        "        #         restored = model(input_)\n",
        "        #     restored = restored[0]\n",
        "\n",
        "        for res,tar in zip(restored,target):\n",
        "            psnr_val_rgb.append(torchPSNR(res, tar))\n",
        "\n",
        "    psnr_val_rgb  = torch.stack(psnr_val_rgb).mean().item()\n",
        "\n",
        "    return psnr_val_rgb"
      ],
      "metadata": {
        "id": "jqtJE21Q04d5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "val_dir = '/content/google-drive/Shareddrives/DeepLearning/skulldatasets/v1/'\n",
        "val_dataset = get_validation_data(val_dir, {'patch_size':256}, input_dir='Nafnet-deblurring/',\n",
        "                            target_dir='traget',)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False, num_workers=4, drop_last=False, pin_memory=True)\n",
        "\n",
        "print(\"Average PSNR between restored images and original images with Denoising Pre-trained model\")\n",
        "print(get_pnsr(val_loader, model=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMYw0h7i07Gd",
        "outputId": "096ca0ff-ed66-4713-ddde-a1a8f937e179"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR between restored images and original images with Denoising Pre-trained model\n",
            "27.468708038330078\n"
          ]
        }
      ]
    }
  ]
}